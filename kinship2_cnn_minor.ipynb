{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simran\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 60, 60, 16)        2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 64)        25664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 128)         204928    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 640)               6636160   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1282      \n",
      "=================================================================\n",
      "Total params: 6,870,450\n",
      "Trainable params: 6,870,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import RandomNormal\n",
    "\n",
    "WTInit = RandomNormal(mean=0.0, stddev=0.01, seed=5)\n",
    "model=Sequential()\n",
    "model.add(Convolution2D(16, (5, 5), input_shape=(64, 64, 6), activation=\"relu\", kernel_initializer=WTInit, bias_initializer=\"zeros\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, (5, 5), activation=\"relu\", kernel_initializer=WTInit, bias_initializer=\"zeros\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(128, (5, 5), activation=\"relu\", kernel_initializer=WTInit, bias_initializer=\"zeros\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(640, activation=\"relu\", kernel_initializer=WTInit, bias_initializer=\"zeros\"))\n",
    "model.add(Dense(2, activation=\"softmax\", kernel_initializer=WTInit, bias_initializer=\"zeros\"))\n",
    "\n",
    "sgd = SGD(lr= 0.01, momentum=0.9, decay=0.005)\n",
    "model.compile(optimizer=sgd, loss=\"categorical_crossentropy\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "\n",
    "#def LoadData(DS='KinFaceW-I'):\n",
    "#mat_fd = scipy.io.loadmat(DS + '/fd_pairs.mat')\n",
    "#s = DS + '/images/'+ string[m]\n",
    "#s =  '/images/'+ string[m]\n",
    "def LoadData():\n",
    "\tcount=0\n",
    "\tall_images=[]\n",
    "\tKin = pd.DataFrame(columns=['Fold', 'Kin/Not-Kin'])\n",
    "\n",
    "\tmat_fd = scipy.io.loadmat( 'fd_pairs_2.mat')\n",
    "\tmat_fd = mat_fd[\"pairs\"]\n",
    "\tmat_fs = scipy.io.loadmat('fs_pairs_2.mat')\n",
    "\tmat_fs = mat_fs[\"pairs\"]\n",
    "\tmat_md = scipy.io.loadmat('md_pairs_2.mat')\n",
    "\tmat_md = mat_md[\"pairs\"]\n",
    "\tmat_ms = scipy.io.loadmat('ms_pairs_2.mat')\n",
    "\tmat_ms = mat_ms[\"pairs\"]\n",
    "\n",
    "\tMat = [mat_fd, mat_fs, mat_md, mat_ms]\n",
    "\tstring = ['father-dau_2/fd_', 'father-son_2/fs_', 'mother-dau_2/md_', 'mother-son_2/ms_']\n",
    "\n",
    "\tfor m in range(0, 4):\n",
    "\t\tfor j in range(0, Mat[m].shape[0]):\n",
    "\t\t\ts =  string[m]\n",
    "\t\t\taddr = s + Mat[m][j][2][0][3:6]\n",
    "\t\t\timage1 = imageio.imread(addr +'_1.jpg')\t\n",
    "\t\t\taddr = s + Mat[m][j][3][0][3:6]  \n",
    "\t\t\timage2 = imageio.imread(addr +'_2.jpg')\n",
    "\t\t\tKin.loc[count] = [Mat[m][j][0][0][0], Mat[m][j][1][0][0]]\n",
    "\t\t\tnew_image = np.concatenate((image1, image2), axis=2)\n",
    "\t\t\tall_images+=[np.array(new_image)]\n",
    "\t\t\tcount+=1\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "\tall_images = np.array(all_images)\n",
    "\tall_images = all_images.astype('float32')\n",
    "\tall_images -= np.mean(all_images, axis=0)\n",
    "\tall_images /= np.std(all_images, axis=0)\n",
    "\tKin = np.array(Kin)\n",
    "\tData = [all_images, Kin]\n",
    "\n",
    "\trng_state = np.random.get_state()\n",
    "\tnp.random.shuffle(all_images)\n",
    "\tnp.random.set_state(rng_state)\n",
    "\tnp.random.shuffle(Kin) \n",
    "\n",
    "\tFolds = [[[], []], [[], []], [[], []], [[], []], [[], []]]\n",
    "\tfor i in range (0, all_images.shape[0]):\n",
    "\t\tfor j in range(0, 5):\n",
    "\t\t\tif(Data[1][i][0]==j+1):\n",
    "\t\t\t\tFolds[j] = np.append(Folds[j], [[np.array(all_images[i])], [np.array(Kin[i])]], axis=1)\n",
    "\n",
    "\tX=[[], [], [], [], []]\n",
    "\tY=[[], [], [], [], []] \n",
    "\tfor i in range(0, 5): \n",
    "\t\tX[i] = np.array(Folds[i][0])\n",
    "\t\tY[i] = np.array([Folds[i][1][j][1] for j in range(Folds[i].shape[1])]) \n",
    "\n",
    "\tX_Train=[[], [], [], [], []] \n",
    "\tY_Train=[[], [], [], [], []]    \n",
    "\tX_Test=[[], [], [], [], []]\n",
    "\tY_Test=[[], [], [], [], []]    \n",
    "    \n",
    "\tfor i in range(0, 5):    \n",
    "\t\tX_Train[i] = np.append(X[i%5], X[(i+1)%5], axis=0)\n",
    "\t\tX_Train[i] = np.append(X_Train[i], X[(i+2)%5], axis=0)\n",
    "\t\tX_Train[i] = np.append(X_Train[i], X[(i+3)%5], axis=0)\n",
    "\t\tY_Train[i] = np.append(Y[i%5], Y[(i+1)%5], axis=0)\n",
    "\t\tY_Train[i] = np.append(Y_Train[i], Y[(i+2)%5], axis=0)\n",
    "\t\tY_Train[i] = np.append(Y_Train[i], Y[(i+3)%5], axis=0)\n",
    "\t\tX_Test[i] = X[(i+4)%5]\n",
    "\t\tY_Test[i] = Y[(i+4)%5]\n",
    "\n",
    "\treturn X_Train, Y_Train, X_Test, Y_Test\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "def CompileModel():\n",
    "\tmodel=Sequential()\n",
    "\tmodel.add(Convolution2D(16, (5, 5), input_shape=(64, 64, 6)))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\tmodel.add(Convolution2D(64, (5, 5)))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\tmodel.add(Convolution2D(256, (5, 5)))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Activation('relu'))\n",
    "\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dropout(0.5))\n",
    "    \n",
    "\tmodel.add(Dense(640))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Activation('relu'))\n",
    "\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(2))\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\n",
    "\tsgd = SGD(lr=0.0001, momentum=0.9, decay=0.005)\n",
    "\tmodel.compile(optimizer='sgd', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\tprint(model.summary())\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 60, 60, 16)        2416      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 60, 60, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 60, 60, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 64)        25664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 9, 9, 256)         409856    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 9, 9, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 20736)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20736)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 640)               13271680  \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 640)               2560      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 1282      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 13,714,802\n",
      "Trainable params: 13,712,850\n",
      "Non-trainable params: 1,952\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/50\n",
      "1600/1600 [==============================] - 122s 76ms/step - loss: 0.8113 - acc: 0.6225 - val_loss: 0.6477 - val_acc: 0.7450\n",
      "Epoch 2/50\n",
      "1600/1600 [==============================] - 116s 72ms/step - loss: 0.5522 - acc: 0.7512 - val_loss: 0.7187 - val_acc: 0.7100\n",
      "Epoch 3/50\n",
      "1600/1600 [==============================] - 125s 78ms/step - loss: 0.4502 - acc: 0.7950 - val_loss: 0.4553 - val_acc: 0.8275\n",
      "Epoch 4/50\n",
      "1600/1600 [==============================] - 115s 72ms/step - loss: 0.4091 - acc: 0.8206 - val_loss: 0.4638 - val_acc: 0.8200\n",
      "Epoch 5/50\n",
      "1600/1600 [==============================] - 131s 82ms/step - loss: 0.3477 - acc: 0.8600 - val_loss: 0.5651 - val_acc: 0.8100\n",
      "Epoch 6/50\n",
      "1600/1600 [==============================] - 112s 70ms/step - loss: 0.3280 - acc: 0.8606 - val_loss: 0.3889 - val_acc: 0.8250\n",
      "Epoch 7/50\n",
      "1600/1600 [==============================] - 103s 64ms/step - loss: 0.2917 - acc: 0.8862 - val_loss: 0.3939 - val_acc: 0.8400\n",
      "Epoch 8/50\n",
      "1600/1600 [==============================] - 125s 78ms/step - loss: 0.3028 - acc: 0.8762 - val_loss: 0.4110 - val_acc: 0.8125\n",
      "Epoch 9/50\n",
      "1600/1600 [==============================] - 122s 76ms/step - loss: 0.2756 - acc: 0.8837 - val_loss: 0.3553 - val_acc: 0.8450\n",
      "Epoch 10/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.2643 - acc: 0.8912 - val_loss: 0.3437 - val_acc: 0.8500\n",
      "Epoch 11/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.2282 - acc: 0.9031 - val_loss: 0.3614 - val_acc: 0.8350\n",
      "Epoch 12/50\n",
      "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2062 - acc: 0.9125 - val_loss: 0.3524 - val_acc: 0.8450\n",
      "Epoch 13/50\n",
      "1600/1600 [==============================] - 115s 72ms/step - loss: 0.1988 - acc: 0.9175 - val_loss: 0.3653 - val_acc: 0.8600\n",
      "Epoch 14/50\n",
      "1600/1600 [==============================] - 126s 78ms/step - loss: 0.1899 - acc: 0.9156 - val_loss: 0.3735 - val_acc: 0.8475\n",
      "Epoch 15/50\n",
      "1600/1600 [==============================] - 117s 73ms/step - loss: 0.2089 - acc: 0.9100 - val_loss: 0.3289 - val_acc: 0.8475\n",
      "Epoch 16/50\n",
      "1600/1600 [==============================] - 116s 73ms/step - loss: 0.1767 - acc: 0.9263 - val_loss: 0.3443 - val_acc: 0.8575\n",
      "Epoch 17/50\n",
      "1600/1600 [==============================] - 110s 69ms/step - loss: 0.1648 - acc: 0.9306 - val_loss: 0.3305 - val_acc: 0.8675\n",
      "Epoch 18/50\n",
      "1600/1600 [==============================] - 120s 75ms/step - loss: 0.1796 - acc: 0.9250 - val_loss: 0.3402 - val_acc: 0.8500\n",
      "Epoch 19/50\n",
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.1479 - acc: 0.9425 - val_loss: 0.3781 - val_acc: 0.8500\n",
      "Epoch 20/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.1359 - acc: 0.9506 - val_loss: 0.3347 - val_acc: 0.8675\n",
      "Epoch 21/50\n",
      "1600/1600 [==============================] - 113s 70ms/step - loss: 0.1587 - acc: 0.9363 - val_loss: 0.3465 - val_acc: 0.8500\n",
      "Epoch 22/50\n",
      "1600/1600 [==============================] - 117s 73ms/step - loss: 0.1417 - acc: 0.9469 - val_loss: 0.3602 - val_acc: 0.8550\n",
      "Epoch 23/50\n",
      "1600/1600 [==============================] - 116s 73ms/step - loss: 0.1239 - acc: 0.9556 - val_loss: 0.3683 - val_acc: 0.8475\n",
      "Epoch 24/50\n",
      "1600/1600 [==============================] - 113s 71ms/step - loss: 0.1098 - acc: 0.9644 - val_loss: 0.3577 - val_acc: 0.8525\n",
      "Epoch 25/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.1214 - acc: 0.9481 - val_loss: 0.3478 - val_acc: 0.8525\n",
      "Epoch 26/50\n",
      "1600/1600 [==============================] - 128s 80ms/step - loss: 0.1156 - acc: 0.9575 - val_loss: 0.3930 - val_acc: 0.8525\n",
      "Epoch 27/50\n",
      "1600/1600 [==============================] - 97s 60ms/step - loss: 0.1194 - acc: 0.9594 - val_loss: 0.3859 - val_acc: 0.8500\n",
      "Epoch 28/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.1062 - acc: 0.9625 - val_loss: 0.3838 - val_acc: 0.8525\n",
      "Epoch 29/50\n",
      "1600/1600 [==============================] - 92s 58ms/step - loss: 0.0929 - acc: 0.9637 - val_loss: 0.3522 - val_acc: 0.8600\n",
      "Epoch 30/50\n",
      "1600/1600 [==============================] - 97s 61ms/step - loss: 0.1077 - acc: 0.9594 - val_loss: 0.3749 - val_acc: 0.8525\n",
      "Epoch 31/50\n",
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.1054 - acc: 0.9606 - val_loss: 0.3417 - val_acc: 0.8625\n",
      "Epoch 32/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.0775 - acc: 0.9763 - val_loss: 0.3486 - val_acc: 0.8675\n",
      "Epoch 33/50\n",
      "1600/1600 [==============================] - 92s 58ms/step - loss: 0.0717 - acc: 0.9775 - val_loss: 0.3604 - val_acc: 0.8675\n",
      "Epoch 34/50\n",
      "1600/1600 [==============================] - 92s 57ms/step - loss: 0.0796 - acc: 0.9713 - val_loss: 0.3765 - val_acc: 0.8675\n",
      "Epoch 35/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.0664 - acc: 0.9838 - val_loss: 0.3855 - val_acc: 0.8600\n",
      "Epoch 36/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0811 - acc: 0.9688 - val_loss: 0.3812 - val_acc: 0.8550\n",
      "Epoch 37/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0978 - acc: 0.9675 - val_loss: 0.3829 - val_acc: 0.8650\n",
      "Epoch 38/50\n",
      "1600/1600 [==============================] - 92s 57ms/step - loss: 0.0646 - acc: 0.9819 - val_loss: 0.3577 - val_acc: 0.8625\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 92s 58ms/step - loss: 0.0662 - acc: 0.9763 - val_loss: 0.3725 - val_acc: 0.8575\n",
      "Epoch 40/50\n",
      "1600/1600 [==============================] - 99s 62ms/step - loss: 0.0770 - acc: 0.9756 - val_loss: 0.3804 - val_acc: 0.8475\n",
      "Epoch 41/50\n",
      "1600/1600 [==============================] - 112s 70ms/step - loss: 0.0710 - acc: 0.9731 - val_loss: 0.3988 - val_acc: 0.8625\n",
      "Epoch 42/50\n",
      "1600/1600 [==============================] - 107s 67ms/step - loss: 0.0716 - acc: 0.9731 - val_loss: 0.4081 - val_acc: 0.8625\n",
      "Epoch 43/50\n",
      "1600/1600 [==============================] - 105s 66ms/step - loss: 0.0659 - acc: 0.9781 - val_loss: 0.3603 - val_acc: 0.8700\n",
      "Epoch 44/50\n",
      "1600/1600 [==============================] - 113s 71ms/step - loss: 0.0595 - acc: 0.9794 - val_loss: 0.3812 - val_acc: 0.8475\n",
      "Epoch 45/50\n",
      "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0489 - acc: 0.9838 - val_loss: 0.4450 - val_acc: 0.8375\n",
      "Epoch 46/50\n",
      "1600/1600 [==============================] - 110s 69ms/step - loss: 0.0390 - acc: 0.9931 - val_loss: 0.3883 - val_acc: 0.8550\n",
      "Epoch 47/50\n",
      "1600/1600 [==============================] - 98s 61ms/step - loss: 0.0463 - acc: 0.9881 - val_loss: 0.3795 - val_acc: 0.8625\n",
      "Epoch 48/50\n",
      "1600/1600 [==============================] - 111s 70ms/step - loss: 0.0536 - acc: 0.9800 - val_loss: 0.4855 - val_acc: 0.8475\n",
      "Epoch 49/50\n",
      "1600/1600 [==============================] - 103s 65ms/step - loss: 0.0387 - acc: 0.9906 - val_loss: 0.4472 - val_acc: 0.8450\n",
      "Epoch 50/50\n",
      "1600/1600 [==============================] - 95s 59ms/step - loss: 0.0444 - acc: 0.9875 - val_loss: 0.4087 - val_acc: 0.8575\n",
      "400/400 [==============================] - 10s 26ms/step\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/50\n",
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.1914 - acc: 0.9438 - val_loss: 0.0219 - val_acc: 0.9975\n",
      "Epoch 2/50\n",
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.1467 - acc: 0.9456 - val_loss: 0.0165 - val_acc: 0.9975\n",
      "Epoch 3/50\n",
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.1342 - acc: 0.9513 - val_loss: 0.0274 - val_acc: 0.9950\n",
      "Epoch 4/50\n",
      "1600/1600 [==============================] - 97s 60ms/step - loss: 0.1181 - acc: 0.9525 - val_loss: 0.0127 - val_acc: 0.9975\n",
      "Epoch 5/50\n",
      "1600/1600 [==============================] - 99s 62ms/step - loss: 0.1041 - acc: 0.9575 - val_loss: 0.0108 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "1600/1600 [==============================] - 97s 61ms/step - loss: 0.0926 - acc: 0.9650 - val_loss: 0.0234 - val_acc: 0.9950\n",
      "Epoch 7/50\n",
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.0933 - acc: 0.9675 - val_loss: 0.0330 - val_acc: 0.9875\n",
      "Epoch 8/50\n",
      "1600/1600 [==============================] - 99s 62ms/step - loss: 0.0880 - acc: 0.9694 - val_loss: 0.0234 - val_acc: 0.9975\n",
      "Epoch 9/50\n",
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.0986 - acc: 0.9631 - val_loss: 0.0201 - val_acc: 0.9975\n",
      "Epoch 10/50\n",
      "1600/1600 [==============================] - 97s 61ms/step - loss: 0.0903 - acc: 0.9644 - val_loss: 0.0202 - val_acc: 0.9975\n",
      "Epoch 11/50\n",
      "1600/1600 [==============================] - 97s 61ms/step - loss: 0.0510 - acc: 0.9844 - val_loss: 0.0151 - val_acc: 0.9975\n",
      "Epoch 12/50\n",
      "1600/1600 [==============================] - 92s 58ms/step - loss: 0.0626 - acc: 0.9763 - val_loss: 0.0141 - val_acc: 0.9975\n",
      "Epoch 13/50\n",
      "1600/1600 [==============================] - 97s 60ms/step - loss: 0.0606 - acc: 0.9781 - val_loss: 0.0205 - val_acc: 0.9925\n",
      "Epoch 14/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0494 - acc: 0.9838 - val_loss: 0.0214 - val_acc: 0.9950\n",
      "Epoch 15/50\n",
      "1600/1600 [==============================] - 92s 58ms/step - loss: 0.0495 - acc: 0.9812 - val_loss: 0.0213 - val_acc: 0.9950\n",
      "Epoch 16/50\n",
      "1600/1600 [==============================] - 92s 57ms/step - loss: 0.0544 - acc: 0.9825 - val_loss: 0.0280 - val_acc: 0.9950\n",
      "Epoch 17/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.0441 - acc: 0.9856 - val_loss: 0.0220 - val_acc: 0.9950\n",
      "Epoch 18/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.0486 - acc: 0.9881 - val_loss: 0.0275 - val_acc: 0.9925\n",
      "Epoch 19/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0525 - acc: 0.9831 - val_loss: 0.0295 - val_acc: 0.9900\n",
      "Epoch 20/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.0551 - acc: 0.9800 - val_loss: 0.0197 - val_acc: 0.9950\n",
      "Epoch 21/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0302 - acc: 0.9919 - val_loss: 0.0232 - val_acc: 0.9950\n",
      "Epoch 22/50\n",
      "1600/1600 [==============================] - 98s 61ms/step - loss: 0.0531 - acc: 0.9825 - val_loss: 0.0256 - val_acc: 0.9950\n",
      "Epoch 23/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0333 - acc: 0.9913 - val_loss: 0.0170 - val_acc: 0.9950\n",
      "Epoch 24/50\n",
      "1600/1600 [==============================] - 92s 58ms/step - loss: 0.0436 - acc: 0.9875 - val_loss: 0.0179 - val_acc: 0.9950\n",
      "Epoch 25/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.0354 - acc: 0.9900 - val_loss: 0.0198 - val_acc: 0.9975\n",
      "Epoch 26/50\n",
      "1600/1600 [==============================] - 92s 57ms/step - loss: 0.0288 - acc: 0.9913 - val_loss: 0.0203 - val_acc: 0.9950\n",
      "Epoch 27/50\n",
      "1600/1600 [==============================] - 92s 58ms/step - loss: 0.0266 - acc: 0.9931 - val_loss: 0.0195 - val_acc: 0.9950\n",
      "Epoch 28/50\n",
      "1600/1600 [==============================] - 92s 57ms/step - loss: 0.0383 - acc: 0.9881 - val_loss: 0.0337 - val_acc: 0.9900\n",
      "Epoch 29/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.0272 - acc: 0.9944 - val_loss: 0.0256 - val_acc: 0.9950\n",
      "Epoch 30/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0431 - acc: 0.9862 - val_loss: 0.0396 - val_acc: 0.9900\n",
      "Epoch 31/50\n",
      "1600/1600 [==============================] - 92s 58ms/step - loss: 0.0273 - acc: 0.9950 - val_loss: 0.0246 - val_acc: 0.9950\n",
      "Epoch 32/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0209 - acc: 0.9944 - val_loss: 0.0208 - val_acc: 0.9950\n",
      "Epoch 33/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0264 - acc: 0.9913 - val_loss: 0.0255 - val_acc: 0.9950\n",
      "Epoch 34/50\n",
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.0327 - acc: 0.9888 - val_loss: 0.0655 - val_acc: 0.9750\n",
      "Epoch 35/50\n",
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.0343 - acc: 0.9862 - val_loss: 0.0483 - val_acc: 0.9825\n",
      "Epoch 36/50\n",
      "1600/1600 [==============================] - 97s 61ms/step - loss: 0.0282 - acc: 0.9906 - val_loss: 0.0264 - val_acc: 0.9950\n",
      "Epoch 37/50\n",
      "1600/1600 [==============================] - 97s 60ms/step - loss: 0.0398 - acc: 0.9862 - val_loss: 0.0209 - val_acc: 0.9950\n",
      "Epoch 38/50\n",
      "1600/1600 [==============================] - 97s 61ms/step - loss: 0.0299 - acc: 0.9906 - val_loss: 0.0224 - val_acc: 0.9950\n",
      "Epoch 39/50\n",
      "1600/1600 [==============================] - 95s 60ms/step - loss: 0.0346 - acc: 0.9881 - val_loss: 0.0247 - val_acc: 0.9950\n",
      "Epoch 40/50\n",
      "1600/1600 [==============================] - 95s 60ms/step - loss: 0.0234 - acc: 0.9919 - val_loss: 0.0339 - val_acc: 0.9900\n",
      "Epoch 41/50\n",
      "1600/1600 [==============================] - 99s 62ms/step - loss: 0.0243 - acc: 0.9931 - val_loss: 0.0325 - val_acc: 0.9950\n",
      "Epoch 42/50\n",
      "1600/1600 [==============================] - 97s 61ms/step - loss: 0.0172 - acc: 0.9962 - val_loss: 0.0266 - val_acc: 0.9950\n",
      "Epoch 43/50\n",
      "1600/1600 [==============================] - 97s 60ms/step - loss: 0.0165 - acc: 0.9969 - val_loss: 0.0343 - val_acc: 0.9950\n",
      "Epoch 44/50\n",
      "1600/1600 [==============================] - 98s 62ms/step - loss: 0.0204 - acc: 0.9925 - val_loss: 0.0307 - val_acc: 0.9950\n",
      "Epoch 45/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.0162 - acc: 0.9956 - val_loss: 0.0278 - val_acc: 0.9950\n",
      "Epoch 46/50\n",
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.0176 - acc: 0.9969 - val_loss: 0.0281 - val_acc: 0.9925\n",
      "Epoch 47/50\n",
      "1600/1600 [==============================] - 97s 60ms/step - loss: 0.0257 - acc: 0.9925 - val_loss: 0.0289 - val_acc: 0.9950\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.0211 - acc: 0.9925 - val_loss: 0.0268 - val_acc: 0.9925\n",
      "Epoch 49/50\n",
      "1600/1600 [==============================] - 95s 59ms/step - loss: 0.0258 - acc: 0.9913 - val_loss: 0.0258 - val_acc: 0.9925\n",
      "Epoch 50/50\n",
      "1600/1600 [==============================] - 99s 62ms/step - loss: 0.0204 - acc: 0.9956 - val_loss: 0.0327 - val_acc: 0.9925\n",
      "400/400 [==============================] - 10s 25ms/step\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/50\n",
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.0363 - acc: 0.9881 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 2/50\n",
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.0422 - acc: 0.9812 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 3/50\n",
      "1600/1600 [==============================] - 97s 60ms/step - loss: 0.0264 - acc: 0.9925 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "1600/1600 [==============================] - 98s 61ms/step - loss: 0.0414 - acc: 0.9881 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "1600/1600 [==============================] - 97s 61ms/step - loss: 0.0290 - acc: 0.9881 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.0360 - acc: 0.9862 - val_loss: 0.0147 - val_acc: 0.9950\n",
      "Epoch 7/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.0416 - acc: 0.9856 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "1600/1600 [==============================] - 95s 60ms/step - loss: 0.0230 - acc: 0.9944 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.0216 - acc: 0.9937 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "1600/1600 [==============================] - 95s 59ms/step - loss: 0.0157 - acc: 0.9975 - val_loss: 8.0263e-04 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "1600/1600 [==============================] - 95s 59ms/step - loss: 0.0178 - acc: 0.9962 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0222 - acc: 0.9937 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0307 - acc: 0.9913 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "1600/1600 [==============================] - 116s 72ms/step - loss: 0.0194 - acc: 0.9944 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "1600/1600 [==============================] - 129s 80ms/step - loss: 0.0160 - acc: 0.9962 - val_loss: 8.6701e-04 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "1600/1600 [==============================] - 126s 78ms/step - loss: 0.0154 - acc: 0.9975 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "1600/1600 [==============================] - 126s 79ms/step - loss: 0.0145 - acc: 0.9969 - val_loss: 8.1906e-04 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "1600/1600 [==============================] - 129s 81ms/step - loss: 0.0148 - acc: 0.9950 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "1600/1600 [==============================] - 127s 79ms/step - loss: 0.0156 - acc: 0.9975 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "1600/1600 [==============================] - 124s 78ms/step - loss: 0.0188 - acc: 0.9950 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0154 - acc: 0.9950 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "1600/1600 [==============================] - 113s 71ms/step - loss: 0.0089 - acc: 0.9988 - val_loss: 8.3889e-04 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "1600/1600 [==============================] - 113s 71ms/step - loss: 0.0182 - acc: 0.9962 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "1600/1600 [==============================] - 116s 73ms/step - loss: 0.0164 - acc: 0.9931 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "1600/1600 [==============================] - 114s 71ms/step - loss: 0.0169 - acc: 0.9937 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "1600/1600 [==============================] - 110s 69ms/step - loss: 0.0210 - acc: 0.9944 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "1600/1600 [==============================] - 113s 71ms/step - loss: 0.0152 - acc: 0.9962 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "1600/1600 [==============================] - 115s 72ms/step - loss: 0.0132 - acc: 0.9981 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "1600/1600 [==============================] - 113s 70ms/step - loss: 0.0129 - acc: 0.9962 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "1600/1600 [==============================] - 111s 70ms/step - loss: 0.0121 - acc: 0.9981 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.0145 - acc: 0.9956 - val_loss: 8.6610e-04 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0164 - acc: 0.9962 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "1600/1600 [==============================] - 94s 58ms/step - loss: 0.0181 - acc: 0.9944 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.0108 - acc: 0.9975 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0176 - acc: 0.9937 - val_loss: 9.9831e-04 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.0093 - acc: 0.9988 - val_loss: 9.0659e-04 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "1600/1600 [==============================] - 100s 63ms/step - loss: 0.0116 - acc: 0.9969 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "1600/1600 [==============================] - 117s 73ms/step - loss: 0.0135 - acc: 0.9975 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "1600/1600 [==============================] - 116s 72ms/step - loss: 0.0169 - acc: 0.9956 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "1600/1600 [==============================] - 116s 72ms/step - loss: 0.0141 - acc: 0.9969 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "1600/1600 [==============================] - 116s 72ms/step - loss: 0.0110 - acc: 0.9981 - val_loss: 8.8696e-04 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "1600/1600 [==============================] - 118s 74ms/step - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "1600/1600 [==============================] - 117s 73ms/step - loss: 0.0095 - acc: 0.9981 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "1600/1600 [==============================] - 120s 75ms/step - loss: 0.0076 - acc: 0.9994 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "1600/1600 [==============================] - 113s 71ms/step - loss: 0.0087 - acc: 0.9969 - val_loss: 8.5278e-04 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "1600/1600 [==============================] - 120s 75ms/step - loss: 0.0058 - acc: 0.9994 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "1600/1600 [==============================] - 122s 76ms/step - loss: 0.0082 - acc: 0.9988 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "1600/1600 [==============================] - 120s 75ms/step - loss: 0.0120 - acc: 0.9969 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "1600/1600 [==============================] - 119s 74ms/step - loss: 0.0120 - acc: 0.9975 - val_loss: 6.5579e-04 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "1600/1600 [==============================] - 120s 75ms/step - loss: 0.0132 - acc: 0.9975 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "400/400 [==============================] - 12s 29ms/step\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/50\n",
      "1600/1600 [==============================] - 121s 76ms/step - loss: 0.0081 - acc: 0.9988 - val_loss: 2.5522e-04 - val_acc: 1.0000\n",
      "Epoch 2/50\n",
      "1600/1600 [==============================] - 119s 75ms/step - loss: 0.0099 - acc: 0.9981 - val_loss: 2.4044e-04 - val_acc: 1.0000\n",
      "Epoch 3/50\n",
      "1600/1600 [==============================] - 127s 79ms/step - loss: 0.0130 - acc: 0.9962 - val_loss: 2.9555e-04 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "1600/1600 [==============================] - 124s 77ms/step - loss: 0.0090 - acc: 0.9969 - val_loss: 2.6191e-04 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "1600/1600 [==============================] - 125s 78ms/step - loss: 0.0080 - acc: 0.9975 - val_loss: 2.0780e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "1600/1600 [==============================] - 124s 77ms/step - loss: 0.0171 - acc: 0.9937 - val_loss: 2.4509e-04 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "1600/1600 [==============================] - 124s 77ms/step - loss: 0.0147 - acc: 0.9975 - val_loss: 7.0704e-04 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "1600/1600 [==============================] - 124s 77ms/step - loss: 0.0183 - acc: 0.9937 - val_loss: 3.9439e-04 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "1600/1600 [==============================] - 124s 77ms/step - loss: 0.0126 - acc: 0.9956 - val_loss: 5.1913e-04 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "1600/1600 [==============================] - 124s 77ms/step - loss: 0.0187 - acc: 0.9906 - val_loss: 3.2643e-04 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "1600/1600 [==============================] - 126s 78ms/step - loss: 0.0232 - acc: 0.9931 - val_loss: 4.3817e-04 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "1600/1600 [==============================] - 107s 67ms/step - loss: 0.0107 - acc: 0.9975 - val_loss: 5.9254e-04 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0067 - acc: 0.9988 - val_loss: 4.4462e-04 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.0058 - acc: 0.9988 - val_loss: 4.5563e-04 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "1600/1600 [==============================] - 99s 62ms/step - loss: 0.0105 - acc: 0.9962 - val_loss: 2.7740e-04 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "1600/1600 [==============================] - 97s 61ms/step - loss: 0.0081 - acc: 0.9981 - val_loss: 2.8224e-04 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "1600/1600 [==============================] - 92s 57ms/step - loss: 0.0123 - acc: 0.9969 - val_loss: 3.4516e-04 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.0123 - acc: 0.9950 - val_loss: 3.2434e-04 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0093 - acc: 0.9975 - val_loss: 5.0050e-04 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "1600/1600 [==============================] - 90s 56ms/step - loss: 0.0078 - acc: 0.9981 - val_loss: 2.8243e-04 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "1600/1600 [==============================] - 102s 64ms/step - loss: 0.0064 - acc: 0.9988 - val_loss: 3.3736e-04 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "1600/1600 [==============================] - 101s 63ms/step - loss: 0.0089 - acc: 0.9969 - val_loss: 6.4355e-04 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.0145 - acc: 0.9969 - val_loss: 7.7489e-04 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "1600/1600 [==============================] - 103s 64ms/step - loss: 0.0069 - acc: 0.9988 - val_loss: 5.6034e-04 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "1600/1600 [==============================] - 112s 70ms/step - loss: 0.0103 - acc: 0.9969 - val_loss: 2.7855e-04 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0079 - acc: 0.9969 - val_loss: 4.4371e-04 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "1600/1600 [==============================] - 97s 61ms/step - loss: 0.0057 - acc: 0.9994 - val_loss: 3.3942e-04 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "1600/1600 [==============================] - 97s 61ms/step - loss: 0.0118 - acc: 0.9944 - val_loss: 4.9653e-04 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.0070 - acc: 0.9975 - val_loss: 2.9122e-04 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "1600/1600 [==============================] - 98s 61ms/step - loss: 0.0066 - acc: 0.9981 - val_loss: 5.9770e-04 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "1600/1600 [==============================] - 100s 62ms/step - loss: 0.0095 - acc: 0.9988 - val_loss: 2.9724e-04 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "1600/1600 [==============================] - 110s 69ms/step - loss: 0.0040 - acc: 0.9994 - val_loss: 2.4938e-04 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "1600/1600 [==============================] - 99s 62ms/step - loss: 0.0089 - acc: 0.9969 - val_loss: 4.9823e-04 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "1600/1600 [==============================] - 98s 61ms/step - loss: 0.0083 - acc: 0.9975 - val_loss: 3.2647e-04 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "1600/1600 [==============================] - 101s 63ms/step - loss: 0.0081 - acc: 0.9994 - val_loss: 3.6546e-04 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "1600/1600 [==============================] - 112s 70ms/step - loss: 0.0092 - acc: 0.9962 - val_loss: 3.2454e-04 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0089 - acc: 0.9962 - val_loss: 2.6134e-04 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "1600/1600 [==============================] - 105s 65ms/step - loss: 0.0073 - acc: 0.9988 - val_loss: 1.9698e-04 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "1600/1600 [==============================] - 103s 64ms/step - loss: 0.0099 - acc: 0.9962 - val_loss: 5.4250e-04 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "1600/1600 [==============================] - 96s 60ms/step - loss: 0.0085 - acc: 0.9975 - val_loss: 2.7868e-04 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "1600/1600 [==============================] - 99s 62ms/step - loss: 0.0076 - acc: 0.9994 - val_loss: 2.5839e-04 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "1600/1600 [==============================] - 114s 71ms/step - loss: 0.0053 - acc: 0.9994 - val_loss: 3.1367e-04 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "1600/1600 [==============================] - 107s 67ms/step - loss: 0.0043 - acc: 0.9994 - val_loss: 3.2621e-04 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "1600/1600 [==============================] - 108s 68ms/step - loss: 0.0068 - acc: 0.9988 - val_loss: 2.8429e-04 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "1600/1600 [==============================] - 107s 67ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 2.4126e-04 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.0073 - acc: 0.9988 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0067 - acc: 0.9981 - val_loss: 7.4562e-04 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "1600/1600 [==============================] - 92s 58ms/step - loss: 0.0085 - acc: 0.9981 - val_loss: 3.4416e-04 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "1600/1600 [==============================] - 90s 56ms/step - loss: 0.0077 - acc: 0.9981 - val_loss: 6.7458e-04 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "1600/1600 [==============================] - 95s 59ms/step - loss: 0.0078 - acc: 0.9981 - val_loss: 2.7534e-04 - val_acc: 1.0000\n",
      "400/400 [==============================] - 10s 24ms/step\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/50\n",
      "1600/1600 [==============================] - 90s 56ms/step - loss: 0.0063 - acc: 0.9988 - val_loss: 1.3858e-04 - val_acc: 1.0000\n",
      "Epoch 2/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0066 - acc: 0.9994 - val_loss: 9.8722e-05 - val_acc: 1.0000\n",
      "Epoch 3/50\n",
      "1600/1600 [==============================] - 90s 56ms/step - loss: 0.0089 - acc: 0.9975 - val_loss: 1.2073e-04 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0131 - acc: 0.9956 - val_loss: 1.6185e-04 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0085 - acc: 0.9969 - val_loss: 1.3672e-04 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0164 - acc: 0.9944 - val_loss: 1.4469e-04 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0082 - acc: 0.9975 - val_loss: 9.3062e-05 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "1600/1600 [==============================] - 92s 58ms/step - loss: 0.0120 - acc: 0.9962 - val_loss: 2.2438e-04 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "1600/1600 [==============================] - 90s 56ms/step - loss: 0.0124 - acc: 0.9962 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "1600/1600 [==============================] - 92s 58ms/step - loss: 0.0055 - acc: 0.9981 - val_loss: 3.0270e-04 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0075 - acc: 0.9969 - val_loss: 2.3032e-04 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "1600/1600 [==============================] - 4780s 3s/step - loss: 0.0150 - acc: 0.9944 - val_loss: 1.6672e-04 - val_acc: 1.0000\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 92s 58ms/step - loss: 0.0126 - acc: 0.9956 - val_loss: 1.2746e-04 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.0177 - acc: 0.9944 - val_loss: 2.6195e-04 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0076 - acc: 0.9981 - val_loss: 2.0502e-04 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0062 - acc: 0.9988 - val_loss: 1.7381e-04 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0076 - acc: 0.9981 - val_loss: 1.2117e-04 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "1600/1600 [==============================] - 90s 57ms/step - loss: 0.0133 - acc: 0.9950 - val_loss: 8.5781e-04 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0110 - acc: 0.9969 - val_loss: 1.9614e-04 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "1600/1600 [==============================] - 89s 56ms/step - loss: 0.0063 - acc: 0.9988 - val_loss: 1.5076e-04 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "1600/1600 [==============================] - 94s 59ms/step - loss: 0.0109 - acc: 0.9962 - val_loss: 2.5884e-04 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0060 - acc: 0.9988 - val_loss: 1.5117e-04 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0110 - acc: 0.9950 - val_loss: 1.2311e-04 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "1600/1600 [==============================] - 94s 58ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 1.3556e-04 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "1600/1600 [==============================] - 90s 56ms/step - loss: 0.0093 - acc: 0.9975 - val_loss: 1.0433e-04 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "1600/1600 [==============================] - 89s 56ms/step - loss: 0.0052 - acc: 0.9988 - val_loss: 1.0904e-04 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0151 - acc: 0.9962 - val_loss: 2.8772e-04 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "1600/1600 [==============================] - 90s 56ms/step - loss: 0.0065 - acc: 0.9975 - val_loss: 1.6075e-04 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "1600/1600 [==============================] - 90s 56ms/step - loss: 0.0070 - acc: 0.9975 - val_loss: 2.1004e-04 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "1600/1600 [==============================] - 90s 56ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 1.3119e-04 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "1600/1600 [==============================] - 7977s 5s/step - loss: 0.0041 - acc: 0.9994 - val_loss: 2.0148e-04 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "1600/1600 [==============================] - 98s 61ms/step - loss: 0.0046 - acc: 0.9981 - val_loss: 1.0606e-04 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 9.4945e-05 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0090 - acc: 0.9962 - val_loss: 1.6046e-04 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "1600/1600 [==============================] - 90s 56ms/step - loss: 0.0039 - acc: 0.9988 - val_loss: 9.4979e-05 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 1.1816e-04 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0071 - acc: 0.9975 - val_loss: 1.2018e-04 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "1600/1600 [==============================] - 95s 59ms/step - loss: 0.0070 - acc: 0.9988 - val_loss: 1.7502e-04 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0040 - acc: 0.9994 - val_loss: 2.5114e-04 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0055 - acc: 0.9981 - val_loss: 9.8257e-05 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "1600/1600 [==============================] - 92s 58ms/step - loss: 0.0130 - acc: 0.9969 - val_loss: 1.7320e-04 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "1600/1600 [==============================] - 92s 57ms/step - loss: 0.0084 - acc: 0.9975 - val_loss: 1.5006e-04 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0116 - acc: 0.9969 - val_loss: 2.7039e-04 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0102 - acc: 0.9962 - val_loss: 2.9393e-04 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "1600/1600 [==============================] - 92s 58ms/step - loss: 0.0046 - acc: 0.9988 - val_loss: 1.9496e-04 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "1600/1600 [==============================] - 91s 57ms/step - loss: 0.0031 - acc: 0.9994 - val_loss: 1.3521e-04 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "1600/1600 [==============================] - 93s 58ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 1.1566e-04 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "1600/1600 [==============================] - 119s 74ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 1.3853e-04 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "1600/1600 [==============================] - 227s 142ms/step - loss: 0.0035 - acc: 0.9994 - val_loss: 1.0074e-04 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "1600/1600 [==============================] - 177s 111ms/step - loss: 0.0056 - acc: 0.9981 - val_loss: 1.5680e-04 - val_acc: 1.0000\n",
      "400/400 [==============================] - 10s 24ms/step\n",
      "Loss: 0.08856879505536927\n",
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/inertfluid/.config/spyder-py3/')\n",
    "\n",
    "#from DataPreProcess import LoadData\n",
    "#from ModelCompiler import CompileModel\n",
    "\n",
    "DataSet = 'KinFaceW-II'\n",
    "model = CompileModel()\n",
    "X_Train, Y_Train, X_Test, Y_Test = LoadData()\n",
    "\n",
    "score=[]\n",
    "for j in range(0, 5):\n",
    "    X_Train[j] = np.reshape(list(X_Train[j]), (X_Train[j].shape[0], 64, 64, 6))\n",
    "    Y_Train[j] = keras.utils.to_categorical(Y_Train[j], 2)\n",
    "    X_Test[j] = np.reshape(list(X_Test[j]), (X_Test[j].shape[0], 64, 64, 6))\n",
    "    Y_Test[j] = keras.utils.to_categorical(Y_Test[j], 2)\n",
    "    model.fit(X_Train[j], Y_Train[j], batch_size=64, epochs=50, validation_data=(X_Test[j], Y_Test[j]), shuffle=True)\n",
    "    score+=[model.evaluate(X_Test[j], Y_Test[j], verbose=1)]\n",
    "    \n",
    "score=np.array(score)\n",
    "loss = np.average(score.T[0])\n",
    "accuracy = np.average(score.T[1])\n",
    "\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
